# PKMS Backend Dependencies
# Each dependency is annotated with its purpose, key features, and approx. installed size (if significant).
# Remove dev/test-only packages for production to reduce image size.

# --- FastAPI and ASGI Server ---
fastapi==0.104.1           # 🚀 Main web framework (async, OpenAPI, validation)
uvicorn[standard]==0.24.0  # ⚡ ASGI server for FastAPI (hot reload, websockets)
gunicorn==21.2.0           # 🏭 Production WSGI server (for compatibility, not used with FastAPI directly)

# --- Database and ORM ---
sqlalchemy[asyncio]==2.0.23 # 🗄️  ORM, async DB support, migrations (~23MB)
alembic==1.12.1             # 🔄 DB migrations for SQLAlchemy
aiosqlite==0.19.0           # 🐬 Async SQLite driver (for local dev)

# --- Authentication and Security ---
passlib[bcrypt]==1.7.4      # 🔒 Password hashing (bcrypt, argon2, etc.) (~4.3MB)
python-jose[cryptography]==3.3.0 # 🔑 JWT, JWE, JWS (token auth)
python-multipart==0.0.6     # 📦 Multipart form parsing (file uploads)

# --- Rate Limiting and Security ---
slowapi==0.1.9              # 🚦 Rate limiting for FastAPI (DoS protection)

# --- File Handling ---
aiofiles==23.2.1            # 📂 Async file I/O (uploads, downloads)
python-magic==0.4.27        # 🧙 File type detection (libmagic)
pillow==10.1.0              # 🖼️  Image processing (resize, convert, thumbnails) (~9MB)

# --- PDF and Document Processing ---
PyMuPDF>=1.23.0             # 📚 PREFERRED: Fast PDF text/image extraction (fitz) (~60MB)
                            # ✅ Why PyMuPDF over PyPDF2?
                            # - 50x faster text extraction
                            # - Superior handling of complex/scanned PDFs  
                            # - Image extraction capabilities
                            # - Better for document search (PKMS core feature)
                            # - Memory efficient for large files
                            # PyPDF2 would save 58MB but too slow for PKMS needs
python-docx>=1.1.0          # 📝 MS Word .docx parsing (text extraction)

# --- Smart Tagging with Transformers (Lightweight) ---
transformers==4.36.0        # 🧠 Hugging Face transformers for smart tagging (~200MB)
                            # ✅ Smart tagging functionality:
                            # - Text classification and auto-tagging
                            # - Content analysis for documents
                            # - Text summarization for diary entries
                            # - Works with CPU inference (no GPU needed)
                            # - Pre-trained models for various tasks
sentence-transformers==2.2.2 # 🎯 Semantic text similarity (~150MB)
                            # ✅ Advanced text analysis:
                            # - Smart content linking between modules
                            # - Similar document/note detection
                            # - Semantic search improvements
                            # - Find related content automatically
huggingface-hub==0.19.0     # 🤗 Model downloads and management (~10MB)
                            # ✅ Manages pre-trained models:
                            # - Automatic model downloading
                            # - Model version control and caching
                            # - Lightweight model hub interface

# 🔮 FUTURE AI EXPANSION (DO NOT INSTALL UNLESS USER REQUESTS):
# 
# For Question & Answer capabilities, consider adding:
# - torch==2.1.0 (~800MB) - PyTorch for T5 model support
# - google/flan-t5-small (~300MB) - Question answering from archive content
# - Text-to-text generation for Q&A interface
# - Chat-like interface for knowledge base queries
# 
# Total additional Docker size: ~1.1GB
# Usage: pip install torch transformers[torch]
# Then modify ai_service.py to include T5 Q&A functionality

# --- Utilities ---
python-dateutil>=2.8.2      # 📅 Date/time parsing
pydantic[email]>=2.5.0      # 🛡️  Data validation (FastAPI models)
pydantic-settings>=2.1.0    # ⚙️  Settings management (env vars)

# --- Development and Testing (remove for production) ---
pytest>=7.4.0               # 🧪 Unit testing (dev only, ~3.2MB)
pytest-asyncio>=0.21.0      # 🧪 Async test support (dev only)
httpx>=0.25.0               # 🌐 HTTP client (test/dev only)

# --- Environment variables ---
python-dotenv==1.0.0        # 🌱 Load .env files for config

# --- Security monitoring and logging ---
structlog==23.2.0           # 📊 Structured logging (advanced, not always used)
prometheus-client==0.19.0   # 📈 Prometheus metrics exporter

# --- Input validation and sanitization ---
bleach>=6.1.0               # 🧼 HTML sanitization (XSS protection)

# --- Performance & Caching ---
redis==5.0.1                # 🚀 Redis client (optional, for caching/sessions)
aiocache==0.12.2            # ⚡ Async caching (multi-backend)

# --- Smart Tagging Impact ---
# 🧠 With Transformers: ~1.2GB total Docker image (up from 525MB)
# ├── 🧠 Transformers: ~200MB       ✅ INSTALLED - Smart tagging models
# ├── 🎯 Sentence-transformers: ~150MB ✅ INSTALLED - Semantic analysis
# ├── 🤗 HuggingFace Hub: ~10MB     ✅ INSTALLED - Model management
# └── 📦 Dependencies: ~300MB       ✅ INSTALLED - Supporting libraries
#
# 🔮 FUTURE EXPANSION (optional):
# ├── 🧠 PyTorch: ~800MB           ⏸️ OPTIONAL - T5 Q&A model support
# └── 📚 google/flan-t5-small: ~300MB ⏸️ OPTIONAL - Question answering
#
# 📊 Smart Features (CURRENTLY ACTIVE):
# ✅ Automatic content tagging based on text analysis
# ✅ Smart document categorization (work, personal, research, etc.)
# ✅ Diary entry sentiment and topic analysis
# ✅ Related content suggestions across modules
# ✅ Improved search with semantic similarity
# ✅ Auto-linking between related notes/documents
# ✅ Content summarization capabilities
#
# 🔮 OPTIONAL FEATURES (if PyTorch + T5 added):
# ⏸️ Question answering from archive content (via T5)
# ⏸️ Chat-like interface for knowledge base queries

# --- Size Justification ---
# Transformers add ~700MB to Docker image but provide:
# - Automatic smart tagging (saves hours of manual categorization)
# - Content discovery and cross-module linking
# - Enhanced search with semantic understanding
# - Text summarization for long documents/diary entries
# - Future-ready for advanced AI features
#
# Benefits far outweigh the size cost for a knowledge management system.
# Users can disable AI features if size is critical.

# 📁 /opt (233MB) - Python Virtual Environment
# ├── 🐍 PyMuPDF: 60MB        ✅ USED - PDF processing
# ├── 🗄️ SQLAlchemy: 23MB     ✅ USED - Database ORM
# ├── 📦 pip: 17MB            ✅ USED - Package manager
# ├── ⚡ uvloop: 14MB         ✅ USED - Fast event loop
# ├── 🔐 cryptography: 14MB   ✅ USED - Authentication/security
# ├── 📄 lxml: 12MB           ✅ USED - XML/HTML processing
# ├── 🎨 Pygments: 9.3MB      ❌ NOT USED - Code highlighting
# ├── 🖼️ Pillow.libs: 9.1MB   ✅ USED - Image processing deps
# ├── 🛠️ setuptools: 6.7MB    ✅ USED - Build tools
# ├── ✅ pydantic_core: 5.0MB ✅ USED - Data validation
# ├── 🔒 passlib: 4.3MB      ✅ USED - Password hashing
# ├── 📊 pydantic: 4.1MB     ✅ USED - Data validation
# ├── 🖼️ PIL: 3.5MB          ✅ USED - Image processing
# ├── 🧪 pytest: 3.2MB       ❌ NOT USED IN PROD - Testing
# └── 📝 yaml: 3.0MB         ✅ USED - Config parsing

# 📁 /usr (133MB) - System libraries
# 📁 /var (7.0MB) - Variable data
# 📁 /etc (1.4MB) - Configuration files
# 📁 /app (512KB) - Your application code

# Packages Currently NOT Used (can be removed for production):
# ❌ Pygments (9.3MB) - Code syntax highlighting
# ❌ pytest + pytest-asyncio (3.2MB) - Testing framework
# ❌ httpx (included in deps) - HTTP client for testing
# ❌ structlog - Advanced logging (not in current code)